{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c826873c",
   "metadata": {},
   "source": [
    "# **Clustering des titres**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a9981c",
   "metadata": {},
   "source": [
    "Le but de ce notebook est d'essayer de faire un clustering sur la colonne titres de notre fichier, afin de pouvoir ensuite donner un thème par cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b4313ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Télécharger les stop words français si nécessaire\n",
    "nltk.download('stopwords', quiet=True)\n",
    "french_stop_words = stopwords.words('french')\n",
    "english_stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2b46f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1255\n",
      "Index(['id', 'title', 'year', 'language', 'Nb_authors', 'Nb_male', 'Nb_female',\n",
      "       'theme', 'keywords'],\n",
      "      dtype='object')\n",
      "Index(['id', 'title', 'year', 'language', 'Nb_authors', 'Nb_male', 'Nb_female',\n",
      "       'theme', 'keywords'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Chargement des données \n",
    "data= pd.read_csv(\"articles.csv\")\n",
    "# Nombre d'articles \n",
    "print (data.shape[0])\n",
    "print (data.columns)\n",
    "# Remplacer le nom de la première colonne par \"id\"\n",
    "data.rename(columns={data.columns[0]: \"id\"}, inplace=True)\n",
    "print (data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2162d5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "# Dans le fichier y'a des articles en français et en anglais \n",
    "data_fr = data[data['language'] == 'fr']\n",
    "print (data_fr.shape[0])\n",
    "data_en = data[data['language'] == 'en']\n",
    "print (data_en.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629ba926",
   "metadata": {},
   "source": [
    "# Traitement du français"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d17fcd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "     ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 2.6/16.3 MB 12.5 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 5.2/16.3 MB 12.2 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 6.6/16.3 MB 10.6 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 8.4/16.3 MB 10.0 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 10.2/16.3 MB 9.5 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 11.0/16.3 MB 9.3 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 12.3/16.3 MB 8.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 13.9/16.3 MB 8.2 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 14.9/16.3 MB 7.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  16.3/16.3 MB 7.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  16.3/16.3 MB 7.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 16.3/16.3 MB 6.6 MB/s  0:00:02\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4a2214a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de mots uniques : 1924\n"
     ]
    }
   ],
   "source": [
    "# Récupération du vocabulaire français à partir des titres des articles\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as french_stop_words\n",
    "\n",
    "# Charger le modèle français\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "# Initialiser un set vide pour le vocabulaire\n",
    "vocab_fr = set()\n",
    "\n",
    "for title in data_fr['title']:\n",
    "    doc = nlp(title)\n",
    "    for token in doc:\n",
    "        # garder seulement les mots alphabétiques, minuscules, non stopwords\n",
    "        lemma = token.lemma_.lower()\n",
    "        if token.is_alpha and lemma not in french_stop_words:\n",
    "            vocab_fr.add(lemma)\n",
    "\n",
    "print(\"Nombre de mots uniques :\", len(vocab_fr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "558154be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tri', 'apport', 'codage', 'fichier', 'sensitive', 'géolocalisation', 'relationnelle', 'comparatif', 'comportemental', 'semantique', 'typer', 'proportionnel', 'recherche', 'direct', 'écriture', 'pervasif', 'chaîner', 'log', 'lexicosyntaxique', 'quadratique', 'milieu', 'région', 'basée', 'interpréter', 'multistratégi', 'protéin', 'inventive', 'fréquent', 'progressif', 'party', 'ghsom', 'comparer', 'pratique', 'cluster', 'biodiversité', 'distributivité', 'tendance', 'base', 'artificiel', 'concevoir', 'thésaurus', 'grand', 'légitimement', 'collaboration', 'engendrer', 'diffuseur', 'probabiliste', 'globalisation', 'ashm', 'morphologique', 'emploi', 'régner', 'cycliques', 'transition', 'rôle', 'pureter', 'expression', 'skylin', 'structurel', 'manipulation', 'reuters', 'vote', 'gml', 'détail', 'issu', 'partir', 'corpus', 'équivalence', 'tmd', 'fouille', 'format', 'compact', 'causalité', 'arbre', 'diachronique', 'rayonnement', 'ppmi', 'chirurgie', 'navigation', 'commercial', 'programme', 'accumulation', 'fed', 'choquet', 'polluer', 'inattendu', 'oraler', 'découverte', 'statique', 'précision', 'linguistique', 'approche', 'robuste', 'histogramme', 'perte', 'tln', 'prototype', 'pcar', 'ferré', 'empreinte', 'efficacement', 'latent', 'antique', 'parcours', 'profil', 'mask', 'affichage', 'priori', 'automatiquement', 'ensemblistes', 'simplifier', 'combiner', 'nettoyage', 'représentatif', 'diffusion', 'créatif', 'moindre', 'consensus', 'biomédical', 'agroalimentaire', 'mining', 'améliorer', 'skyline', 'gene', 'graphe', 'supervisée', 'structures', 'borne', 'classification', 'simulateur', 'poi', 'cartographique', 'prédictif', 'contenu', 'résumés', 'faibler', 'large', 'influenceur', 'ppc', 'presse', 'plainte', 'isicil', 'traminer', 'laplacien', 'cart', 'xml', 'appliquer', 'limiter', 'statistiquement', 'calcul', 'particulièrement', 'centralité', 'fondé', 'compatibilité', 'hétérogène', 'support', 'imc', 'hôtel', 'partitionnement', 'chaîné', 'factoriel', 'siad', 'paramétrique', 'discrétisation', 'solution', 'régression', 'lak', 'entrpôt', 'ascendant', 'nfb', 'caractériser', 'limite', 'indicateur', 'état', 'traduction', 'siam', 'décisionnelles', 'odeur', 'récent', 'coefficient', 'multivarier', 'opérateur', 'fragment', 'règles', 'notion', 'invariant', 'agent', 'eiah', 'libéral', 'chic', 'petit', 'acp', 'expansion', 'processus', 'coller', 'graduels', 'hiérarchisation', 'section', 'raisonnemer', 'hiérarchique', 'arles', 'travers', 'réponser', 'prévision', 'principes', 'terminologie', 'moc', 'lexico', 'compréhension', 'rare', 'associative', 'imputation', 'gain', 'cisner', 'français', 'extraction', 'téléphonie', 'norme', 'candidats', 'sommet', 'mémoire', 'distribués', 'négatif', 'découvrir', 'drone', 'multicoeur', 'intéressant', 'textes', 'redondant', 'dépêche', 'potentiellement', 'analogique', 'enrichissement', 'automobiles', 'collection', 'géospatial', 'roc', 'adaptable', 'argumentatif', 'observation', 'courriel', 'élicitation', 'fermée', 'suivi', 'similaire', 'totem', 'means', 'synchronique', 'sac', 'descripteur', 'densité', 'composition', 'intervall', 'sdet', 'appariemer', 'spécialiser', 'télévisées', 'génération', 'automate', 'urbain', 'industriel', 'graphes', 'prémisse', 'choix', 'valider', 'pyramide', 'opérationnel', 'réflexion', 'transformer', 'lien', 'superposer', 'reglo', 'recommander', 'télévisuel', 'bruité', 'formelle', 'unitex', 'territoire', 'cnd', 'étude', 'topologiques', 'exploitation', 'spatiotemporell', 'caractéristique', 'entrer', 'contextualiser', 'alignement', 'inconsistant', 'graduel', 'intégrer', 'représenter', 'lab', 'décomposition', 'matrice', 'cerveau', 'extraire', 'recouvrant', 'hydrologie', 'transduction', 'produit', 'conjoint', 'capitalisation', 'défaillance', 'collaborations', 'cl', 'bases', 'intrusion', 'planning', 'champ', 'série', 'art', 'abstop', 'virtuelle', 'supervision', 'asymétrique', 'réutilisation', 'manquer', 'svm', 'visualiser', 'extensionnel', 'ferroviaire', 'similarité', 'catégorie', 'blog', 'formels', 'vestige', 'churn', 'folksonomie', 'algorithme', 'dépendances', 'liage', 'signature', 'projet', 'adaptation', 'hétérogénéité', 'treillis', 'créativité', 'connaître', 'nommer', 'médiation', 'topic', 'randomisation', 'cycle', 'pédagogique', 'variables', 'faux', 'pondération', 'particulier', 'mesure', 'réduit', 'léger', 'induire', 'subjectivité', 'remarquable', 'préférence', 'généraliste', 'proportion', 'participatif', 'betti', 'gravitationnel', 'personnage', 'thyroïde', 'contraindre', 'clowdflows', 'survenir', 'factorisation', 'interactif', 'communicant', 'tournebool', 'textuel', 'traçabilité', 'tweet', 'intelligent', 'hôpital', 'séquentiels', 'compacité', 'territorial', 'voyage', 'som', 'soda', 'coopératif', 'tactique', 'ligne', 'face', 'thématique', 'itemset', 'citation', 'agrégée', 'nomao', 'formel', 'retroweb', 'fermés', 'essieu', 'prototypicalité', 'substitution', 'ntic', 'parallèle', 'chronologie', 'intervalle', 'optique', 'droit', 'assister', 'cabine', 'initialiser', 'rbf', 'robot', 'evolution', 'gvsr', 'patrimoniale', 'typologie', 'analyse', 'réorganisation', 'méthod', 'centroïd', 'sens', 'item', 'binaire', 'khiops', 'ontologie', 'réduire', 'humain', 'abonné', 'génératif', 'validation', 'source', 'calculatoir', 'optimal', 'mobile', 'zone', 'atanor', 'média', 'bruter', 'accès', 'dynamique', 'cube', 'ouvrage', 'qualitatif', 'aberrer', 'maximal', 'open', 'réciprocité', 'prédictier', 'positif', 'cpu', 'implicative', 'personnalité', 'quantitatif', 'unification', 'enquête', 'culturel', 'sncf', 'maritime', 'conservation', 'sarem', 'abstrait', 'suicidaire', 'temporalité', 'graphémique', 'généraliser', 'enrichir', 'gestion', 'documentaire', 'accessible', 'prépayée', 'étiquette', 'multi', 'révolution', 'désambiguïsation', 'ombre', 'plantation', 'communautaire', 'taxonomique', 'agricole', 'analogiquer', 'volée', 'prédicat', 'score', 'caf', 'compétition', 'client', 'proposition', 'multidimensionnels', 'ontologiques', 'contexte', 'jurisprudence', 'repérage', 'secteur', 'théorie', 'vraisemblance', 'classe', 'thermique', 'évaluer', 'vidéo', 'hydroécologique', 'batch', 'adapter', 'generator', 'solubilité', 'etude', 'aéronef', 'bivariée', 'perforecast', 'traverse', 'fiasco', 'rapn', 'descriptif', 'grâce', 'théorique', 'parcellaire', 'variante', 'bayésiens', 'journalistique', 'communication', 'classer', 'méthode', 'big', 'spécialité', 'attribut', 'changement', 'introduction', 'médiateur', 'hautement', 'stati', 'consommation', 'linéaire', 'bivarié', 'carte', 'syntaxico', 'maladie', 'mdl', 'sémiotique', 'catégoriser', 'passionément', 'intervalles', 'unique', 'social', 'edoi', 'evaluation', 'exception', 'wordnet', 'prescriptive', 'mieux', 'électrique', 'obsolescence', 'organique', 'gpu', 'prédir', 'vigilance', 'etiq', 'exécution', 'gène', 'court', 'redescription', 'fonder', 'régularité', 'anytim', 'jeu', 'fermeture', 'utilisation', 'explorer', 'mainmise', 'élimination', 'présence', 'technologique', 'marquage', 'ontobiotop', 'formalisation', 'outlier', 'ras', 'hydraulique', 'arabe', 'violer', 'texte', 'soft', 'degré', 'markov', 'data', 'environnement', 'élastique', 'compétence', 'bayésien', 'computing', 'spatiotemporelle', 'principal', 'carrière', 'conformité', 'humanité', 'alternative', 'rdbtoonto', 'cybercondriaque', 'algèbre', 'annuaire', 'datawarehous', 'positionnement', 'mobilité', 'inspirer', 'temps', 'comparaison', 'import', 'portail', 'ciblage', 'observatoire', 'vecteur', 'outil', 'correspondance', 'multigraduell', 'devenir', 'lieu', 'expertise', 'asti', 'réécriture', 'journalisme', 'composante', 'passe', 'economique', 'lexical', 'ordonner', 'temporel', 'stabilité', 'pouvoir', 'oblique', 'numérique', 'évolutif', 'sélection', 'convexe', 'articulatoire', 'sonar', 'trafic', 'lier', 'b', 'musée', 'plasmodium', 'usage', 'contextuelles', 'aire', 'avancée', 'syntaxique', 'image', 'ontologique', 'solaire', 'framework', 'transmute', 'multiple', 'influence', 'version', 'spoid', 'légende', 'bayesienne', 'inférence', 'review', 'associer', 'réalisation', 'virtuel', 'spécification', 'multicouche', 'centrée', 'essentiel', 'apprendre', 'histoire', 'homogène', 'impact', 'problème', 'dédier', 'bilingue', 'appropriation', 'for', 'cartes', 'personnel', 'début', 'oubli', 'identification', 'intelligible', 'trace', 'paramétrer', 'global', 'combinerweb', 'audio', 'métabolomique', 'complémentarité', 'valeur', 'label', 'organisation', 'blockchain', 'entropie', 'administratif', 'interprétation', 'justice', 'redondante', 'détermination', 'html', 'transcription', 'prédiction', 'conduite', 'university', 'service', 'financement', 'block', 'logiciel', 'assurance', 'rapport', 'demain', 'ecg', 'crucial', 'axe', 'démarche', 'technologie', 'période', 'syr', 'régularisation', 'savoir', 'csp', 'déséquilibré', 'faciliter', 'classificatoire', 'profondeur', 'mapping', 'financier', 'termino', 'vivre', 'conceptuel', 'biographique', 'dialectal', 'accompagner', 'triadique', 'singularité', 'noyau', 'publication', 'assainissement', 'local', 'expert', 'situer', 'flux', 'instantaner', 'étoile', 'position', 'prétopologiqu', 'infinie', 'falsifier', 'program', 'entité', 'taux', 'informatique', 'arabase', 'contraintes', 'chanson', 'point', 'future', 'k', 'mixer', 'fonction', 'automatisation', 'hybridation', 'dela', 'hiérarchie', 'booloader', 'glose', 'séquentiel', 'générique', 'partition', 'maya', 'réputation', 'cible', 'cao', 'maximisation', 'personnaliser', 'moyenne', 'maximum', 'facteur', 'piloter', 'copier', 'acyclique', 'composer', 'hmm', 'cas', 'cyber', 'humanoïde', 'prédicteur', 'abstraite', 'biomédicaux', 'multimédia', 'étendu', 'attribuer', 'industrie', 'structurer', 'informationnel', 'noyal', 'représenté', 'explication', 'évolutionnair', 'neurochirurgical', 'trop', 'cartocel', 'site', 'naïf', 'orienter', 'cours', 'sm', 'groupe', 'maintenance', 'intra', 'radiologique', 'communauter', 'surveillance', 'syntaxe', 'falciparum', 'cancer', 'accord', 'discret', 'langage', 'collectif', 'scoring', 'content', 'exceptionnel', 'moteur', 'partiel', 'j', 'étendre', 'propriété', 'corrélation', 'dictionnaire', 'domicile', 'obèse', 'posteriori', 'réanimation', 'stéréoscopie', 'préparation', 'métrique', 'peuplement', 'réclamation', 'dense', 'conclusion', 'cohérence', 'contamination', 'autour', 'microbien', 'scientométriqu', 'orienté', 'séquence', 'assemblage', 'témoin', 'hiéarchique', 'adaptatif', 'requête', 'géométrie', 'actionnabilité', 'indexation', 'acabit', 'complètement', 'ip', 'argumentation', 'sensible', 'conceptuelle', 'temporiser', 'salines', 'hypersmooth', 'cyclone', 'incertitude', 'unitaire', 'anomalie', 'question', 'aid', 'acquisition', 'désagréger', 'décisionnel', 'interrogation', 'étiqueteur', 'rappel', 'nosql', 'proximité', 'test', 'growth', 'mgb', 'tbi', 'contour', 'selection', 'schéma', 'échantillon', 'commun', 'indésirable', 'exploration', 'satellitaire', 'egc', 'avion', 'bon', 'assignation', 'objet', 'caracteristique', 'catégorisation', 'capitaliste', 'non', 'visuel', 'croisé', 'text', 'interdisciplinarité', 'publicité', 'iconique', 'modularité', 'géométrique', 'recouvrement', 'routage', 'porphyry', 'capturer', 'standard', 'automorphisme', 'pmi', 'fx', 'situation', 'reconstruction', 'signal', 'implicatif', 'mammographie', 'satellite', 'résolution', 'suisse', 'produire', 'aspect', 'vipe', 'tic', 'combinaison', 'bibliothèque', 'donnée', 'comptage', 'persorec', 'optimisation', 'poids', 'voisinage', 'explsa', 'librairie', 'homophone', 'puce', 'réaction', 'attribué', 'vue', 'fusion', 'web', 'annotation', 'coli', 'précoce', 'taaable', 'websum', 'généralisation', 'mise', 'mumie', 'subspace', 'quezao', 'fonctionnel', 'robustesse', 'interactive', 'passage', 'récolte', 'informatif', 'eeg', 'words', 'topographique', 'incomplet', 'bayésienne', 'description', 'conversation', 'simplification', 'ricsh', 'interaction', 'épidémiologique', 'utiliser', 'comportements', 'participation', 'bicluster', 'terrain', 'spatialement', 'exhaustif', 'pose', 'accélérer', 'prétopologiquer', 'tacite', 'agréger', 'elem', 'action', 'algorithmes', 'symétrie', 'tulip', 'plateau', 'échelle', 'forage', 'régulation', 'tanagra', 'boycott', 'intégration', 'reformulation', 'modèles', 'entropique', 'risque', 'investissement', 'tableau', 'appui', 'décision', 'pixel', 'equilibrer', 'plagiat', 'besoin', 'floues', 'construction', 'cibl', 'fcp', 'lumière', 'gradient', 'scientifique', 'amo', 'spark', 'taxonomie', 'eda', 'topologie', 'servicesweb', 'r', 'disparité', 'ensemble', 'voisin', 'mapreduce', 'réconciliation', 'génétique', 'extension', 'sax', 'centrer', 'petri', 'bayes', 'vs', 'champignon', 'induction', 'clos', 'thème', 'modélisation', 'expérience', 'métier', 'chorml', 'sql', 'expérimental', 'anti', 'référentiel', 'n', 'préserver', 'compteur', 'spams', 'positives', 'stockage', 'stanford', 'segmenteur', 'slider', 'représentation', 'datamining', 'paysage', 'sentiment', 'théâtre', 'sequencesviewer', 'liste', 'concis', 'coloration', 'maîtrise', 'énumération', 'électricité', 'création', 'centre', 'intérêt', 'exposition', 'flot', 'médicaux', 'investigation', 'itératif', 'émotion', 'automatique', 'lsa', 'ressource', 'résumé', 'nominal', 'caractère', 'condenser', 'charge', 'estimation', 'segmentation', 'sémantique', 'somerdfs', 'structuration', 'génomique', 'arc', 'récursif', 'binary', 'snow', 'réutiliser', 'actif', 'owl', 'routier', 'dbpédia', 'classique', 'froid', 'classificateur', 'capacitaire', 'suspect', 'végétal', 'sigle', 'intimité', 'prise', 'littérature', 'nouveauté', 'long', 'gmm', 'individuel', 'multidimensionnel', 'diamètre', 'transcriptome', 'volume', 'multilabel', 'décideur', 'condensé', 'spatio', 'mixte', 'somme', 'bloc', 'juridique', 'lever', 'parc', 'uniforme', 'article', 'réponse', 'contribution', 'suicid', 'gramlab', 'heuristiques', 'métadonner', 'vol', 'ac', 'coclustering', 'caractérisation', 'inconnu', 'weka', 'allier', 'distinctif', 'programmation', 'stratégie', 'implicite', 'simple', 'transaction', 'opac', 'message', 'gouvernance', 'gtm', 'émergence', 'propositier', 'dimension', 'priver', 'agence', 'cellulaire', 'mouvement', 'lite', 'olap', 'concepts', 'policier', 'nombre', 'fixe', 'édition', 'proximal', 'cohérent', 'réactionnel', 'incrémentales', 'tarification', 'vectorisation', 'hilbert', 'extractin', 'taille', 'résidu', 'graine', 'populaire', 'dafoe', 'kohonen', 'monte', 'indexer', 'désuffixation', 'fermer', 'erroner', 'approximatif', 'détection', 'distribué', 'escherichia', 'anonymiser', 'beaucoup', 'multivaluer', 'activité', 'articleswikipedia', 'récit', 'anormal', 'wiki', 'supplémentaire', 'ancien', 'ingénierie', 'implémentation', 'webmarks', 'synthétiser', 'semi', 'dbfrequentquerie', 'croisement', 'type', 'multidimensionel', 'travail', 'colonne', 'continu', 'cure', 'prix', 'contingence', 'convivail', 'paire', 'personnalisation', 'archive', 'carré', 'spatial', 'patient', 'clés', 'beluga', 'règle', 'plongement', 'automatiser', 'nucléaire', 'centrale', 'divergente', 'idée', 'cop', 'explicatif', 'geodoc', 'météorologiquer', 'topologique', 'stochastique', 'discriminant', 'requêtes', 'dépendre', 'graphique', 'archéologique', 'regard', 'dépendant', 'relationnel', 'résultat', 'échantillonnage', 'xewgraph', 'fourmi', 'catégorieller', 'nature', 'indice', 'c', 'capteur', 'gapit', 'actionnables', 'partage', 'prion', 'orthopédique', 'multicritère', 'quantité', 'sécurité', 'fréquente', 'pléthorique', 'stéréoscopique', 'cibler', 'massif', 'sociabilité', 'vectoriel', 'intelligence', 'molécule', 'crédibiliste', 'citoyen', 'approcheweb', 'propositionaliser', 'définition', 'eau', 'négatives', 'minimal', 'évidentiell', 'radial', 'fréquentes', 'visage', 'phrase', 'conférence', 'bitmap', 'sérier', 'train', 'agronomique', 'protocole', 'contrôle', 'publier', 'haie', 'cler', 'leweb', 'primal', 'phénomène', 'twitter', 'pertinence', 'mélange', 'partiellemer', 'neutralité', 'inter', 'renforcement', 'expérimentations', 'optimiser', 'localisation', 'expliquer', 'impliquer', 'intégrale', 'classifieur', 'masse', 'compromis', 'anglais', 'référence', 'sgbd', 'dimensionnalité', 'sigles', 'ambiance', 'protéine', 'raisonnement', 'navire', 'simultaner', 'java', 'sécuriser', 'spatiales', 'bit', 'statistique', 'parcimonieux', 'intérieur', 'sotree', 'demon', 'sociaux', 'évaluation', 'elaboration', 'galois', 'recette', 'temporellement', 'chaîne', 'icm', 'naturel', 'serveur', 'nautilus', 'marocain', 'temporelle', 'gramme', 'conflit', 'clé', 'pretopolib', 'teximus', 'esiea', 'sein', 'pondérer', 'collaboratif', 'faiblemer', 'psychologique', 'raisonner', 'climatique', 'logique', 'courbe', 'epgy', 'usager', 'production', 'affixe', 'dag', 'discrimination', 'rankmerging', 'latente', 'intégré', 'conceptuels', 'auteur', 'préservation', 'cartogramme', 'locuteur', 'projection', 'streams', 'saffiet', 'politique', 'grammaire', 'plateforme', 'constellation', 'raisonneur', 'transactionnel', 'définir', 'guider', 'moyenner', 'entretien', 'géotechnique', 'décrire', 'equivalence', 'medline', 'coût', 'perspective', 'convergente', 'oeuvre', 'immunitaire', 'sweetdeki', 'uitliation', 'combinatoire', 'prediction', 'professionnel', 'modulaire', 'graph', 'biologique', 'divisiv', 'pouvaient', 'enseignement', 'illustration', 'complexité', 'uml', 'linéarité', 'méthodologie', 'efficace', 'voir', 'méta', 'confrontation', 'apprentissage', 'iceberg', 'vie', 'paradigme', 'analyses', 'performance', 'voyageur', 'fenêtre', 'actualité', 'chimique', 'multilingue', 'bâtiment', 'ressentir', 'audiovisuel', 'prétraitement', 'sociotechnique', 'regrouper', 'pattern', 'symétrique', 'robotiser', 'numériques', 'entreprise', 'cuisine', 'morpho', 'probabilité', 'appel', 'intersection', 'an', 'dopage', 'entrepôt', 'tree', 'videosurveillance', 'air', 'baser', 'diagnostique', 'pcfg', 'ordre', 'télédétection', 'hypertextuel', 'fonctionnement', 'chimie', 'palm', 'mot', 'faire', 'industrialiser', 'domaine', 'connexionniste', 'spectral', 'innovant', 'granularité', 'générateur', 'complexe', 'reconnaissance', 'fia', 'élaboration', 'go', 'famille', 'doux', 'placement', 'architectural', 'universitaire', 'bien', 'dca', 'job', 'générer', 'montant', 'dialogue', 'microblog', 'annoter', 'plate', 'âgé', 'modèle', 'niveau', 'essentiels', 'fabrique', 'élagage', 'notarisation', 'softjaccard', 'coder', 'colorer', 'clique', 'télécom', 'ordinal', 'pharmacovigilance', 'hiérarchiquer', 'irm', 'page', 'haute', 'rapide', 'lem', 'management', 'analytics', 'musical', 'sociologique', 'exploratoire', 'radar', 'anthropocentré', 'obtenir', 'kti', 'distante', 'serveursweb', 'modeling', 'crf', 'étiquetage', 'v', 'vues', 'fodomust', 'analytique', 'réseaux', 'flexible', 'carlo', 'casi', 'asp', 'analyser', 'fabr', 'intelliger', 'microbe', 'campagne', 'meat', 'chute', 'information', 'm', 'transfert', 'procédure', 'cost', 'conception', 'datalab', 'terme', 'pair', 'croyance', 'forum', 'utilisateur', 'afc', 'fast', 'distance', 'chorème', 'traitement', 'exemple', 'propagation', 'seqtree', 'students', 'prospection', 'centré', 'cybercriminelle', 'développement', 'économique', 'diviser', 'réaliste', 'résumer', 'regroupement', 'terminologique', 'concept', 'progiciel', 'gérer', 'coordonnée', 'forme', 'area', 'réalité', 'association', 'orthogonal', 'amélioration', 'symbolique', 'significatif', 'typicalité', 'échange', 'application', 'flou', 'wikis', 'trajectoire', 'amazighe', 'pertinent', 'internet', 'recouvrante', 'ariane', 'bordure', 'accident', 'incertain', 'intrinsèque', 'représentant', 'asymétrie', 'ordonnancement', 'associatif', 'archiview', 'nasopharynx', 'défi', 'dépendance', 'système', 'consistant', 'granulaire', 'problématiques', 'mécaniques', 'historique', 'mesurer', 'interface', 'espace', 'principe', 'wikipédia', 'évènement', 'concordance', 'succès', 'icar', 'incrémental', 'confiance', 'préventif', 'riche', 'eclipse', 'autonome', 'délestage', 'osom', 'enfant', 'spatialisable', 'musique', 'qualité', 'plateform', 'protéique', 'accélération', 'scène', 'contrainte', 'relation', 'évoluer', 'simulation', 'nell', 'vérification', 'rfid', 'compatible', 'algébrique', 'grenoblois', 'sou', 'symboliques', 'inductiver', 'collectivité', 'rendu', 'chemin', 'accessibilité', 'envi', 'défaut', 'conditionnel', 'smo', 'affectation', 'aérien', 'préconisation', 'instance', 'morphosyntaxique', 'volumineuser', 'offre', 'visibilité', 'didactique', 'stable', 'reconstitution', 'associatives', 'répétition', 'public', 'filtrage', 'vision', 'hypergraphe', 'familial', 'santé', 'corréler', 'cognition', 'géographique', 'candidat', 'desesper', 'reconstuire', 'exprimer', 'bibliographique', 'structurellement', 'aléatoire', 'hybride', 'variable', 'réduction', 'gifted', 'commentaire', 'itinéraire', 'transport', 'pgp', 'photographie', 'grille', 'nouvelle', 'incfd', 'implication', 'etl', 'monde', 'allocataire', 'okm', 'inductif', 'imagerie', 'réussite', 'dermatologie', 'adn', 'pleine', 'algeospf', 'bruiter', 'place', 'clustering', 'visual', 'catégoriel', 'multiplexe', 'permettre', 'education', 'architecture', 'classement', 'comportement', 'paramètre', 'biclustering', 'exploiter', 'événement', 'gratuit', 'métadonnée', 'définis', 'démarrage', 'style', 'compte', 'hypermédia', 'date', 'superviser', 'interpersonnel', 'poisson', 'multimedia', 'acka', 'formaliser', 'méthodologique', 'géolocalisé', 'rdf', 'apriori', 'fort', 'recommandation', 'dupliquer', 'moyen', 'performant', 'prétopologie', 'exit', 'lod', 'normalité', 'médical', 'meilleur', 'syntagme', 'géospatiale', 'individu', 'atypique', 'perception', 'discrétiser', 'erreur', 'machine', 'constant', 'aider', 'récurrent', 'dl', 'kd', 'critère', 'ensembliste', 'forêt', 'contextuel', 'cartographie', 'émotionnel', 'patrimoine', 'caméra', 'mammographique', 'arn', 'factuel', 'mooc', 'environnementau', 'affinement', 'génome', 'simultané', 'crowdsourcing', 'couteau', 'prévention', 'kgram', 'scientifiques', 'cadre', 'prédicatif', 'distribution', 'multitemporell', 'paramétrage', 'siècle', 'potentiel', 'capitaliser', 'table', 'agentuml', 'expérimentation', 'peerus', 'semantec', 'credit', 'pétrolier', 'prosopographie', 'extensible', 'prévenir', 'webdocenrich', 'brevet', 'approximative', 'sujet', 'synthèse', 'index', 'suppression', 'chaînage', 'réseau', 'communauté', 'restructuration', 'féminin', 'déséquilibrer', 'distribuer', 'science', 'relaxation', 'imprécis', 'sélectionner', 'chargeur', 'élaguer', 'cinématographique', 'cache', 'ajustable', 'dissimilarité', 'vault', 'stream', 'miner', 'motif', 'interlangue', 'parole', 'croiser', 'lexique', 'complétude', 'filtr', 'manuscrit', 'étiqueter', 'explicite', 'extrait', 'interopérabilité', 'population', 'textuels', 'discours', 'hypertexte', 'technique', 'top', 'marché', 'fonctionnelle', 'logistique', 'défini', 'cognitif', 'émergent', 'biomimétique', 'hospitalier', 'aide', 'structure', 'diagramme', 'mc', 'agrégation', 'contextualisation', 'xquery', 'ciblé', 'mode', 'dc', 'transformation', 'enjeu', 'implantation', 'boosting', 'haptique', 'skypatterns', 'foule', 'libre', 'évolution', 'fondée', 'scénario', 'mixter', 'prior', 'discriminante', 'neurone', 'évidentielle', 'vivant', 'heuristique', 'différence', 'gisement', 'opinion', 'détecteur', 'porteur', 'patron', 'wcum', 'instrumental', 'bdg', 'opération', 'échell', 'ascendante', 'facebook', 'em', 'triangulation', 'complet', 'fp', 'veille', 'registre', 'discriminer', 'diagnostic', 'préfixe', 'knowledge', 'cardiovasculaires', 'gradué', 'kilomètre', 'connaissance', 'imprécision', 'echantillonnage', 'document', 'p', 'obstacle', 'homologue', 'construire', 'inspirée', 'chancellerie', 'réel', 'visualisation', 'rasma', 'redondance', 'france', 'contraposée', 'énoncé', 'bioprocédé', 'comprendre', 'rang', 'chronique', 'sparql', 'épisode', 'drift', 'langue'}\n"
     ]
    }
   ],
   "source": [
    "print(vocab_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "459bd2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1837\n"
     ]
    }
   ],
   "source": [
    "# Nettoyage manuel des mots non pertinents\n",
    "manual_stop_words = {\n",
    "    # Bruit & Lettres isolées\n",
    "    'p', 'n', 'b', 'c', 'j', 'v', 'm', 'r', 'k', 'cl', 'sou', 'tr', 'vs', 'via', 'multi', 'intro', 'chapitre',\n",
    "    \n",
    "    # Termes génériques de recherche\n",
    "    'approche', 'approches', 'méthode', 'méthodes', 'système', 'systèmes',\n",
    "    'application', 'applications', 'analyse', 'analyses', 'étude', 'études',\n",
    "    'modèle', 'modèles', 'modélisation', 'algorithme', 'algorithmes',\n",
    "    'problème', 'problèmes', 'solution', 'solutions', 'résultat', 'résultats',\n",
    "    'outil', 'outils', 'processus', 'technique', 'techniques', 'concept',\n",
    "    'contexte', 'cadre', 'travail', 'travaux',\n",
    "    'contribution', 'contributions', 'cas', 'exemple', 'exemples', 'usage',\n",
    "    'utilisation', 'proposition', 'démarche', 'principe', 'théorie', 'théorique',\n",
    "    'pratique', 'état', 'art', 'vue', 'niveau', 'type', 'moyen', 'question',\n",
    "    'enjeu', 'domaine', 'sujet', \n",
    "    \n",
    "    # Verbes courants (formes lemmatisées probables)\n",
    "    'utiliser', 'permettre', 'baser', 'proposer', 'présenter','définir', 'construire', 'générer', 'traiter',\n",
    "    'extraire', 'apprendre',  'considérer', 'mesurer', 'voir',\n",
    "    'faire', 'obtenir','viser', 'fournir', 'intégrer',\n",
    "    'mettre', 'partir',  'montrer', 'conclure',\n",
    "    \n",
    "    # Adjectifs / Adverbes vagues\n",
    "    'nouveau', 'nouvelle', 'nouveaux', 'nouvelles', 'bon', 'meilleur',\n",
    "    'grand', 'petit', 'simple',\n",
    "    'général', 'efficace', 'performant', 'rapide',  'classique', 'possible',\n",
    "    'nécessaire', 'principal', 'important', 'haut', 'faible', 'large',\n",
    "    'court', 'long', 'très', 'trop', 'peu', 'bien', 'mieux'\n",
    "}\n",
    "vocab_fr = vocab_fr - manual_stop_words\n",
    "print(len(vocab_fr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2db6698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Local\\Temp\\ipykernel_17292\\4166352686.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_fr['title_clean'] = data_fr['title'].apply(clean_title_fr)\n"
     ]
    }
   ],
   "source": [
    "# Créons une colonne titre_clean en les mettant en miniscule sans stop word et en lemme \n",
    "def clean_title_fr(text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_.lower() \n",
    "                     for token in doc \n",
    "                     if token.is_alpha and token.lemma_.lower() not in french_stop_words])\n",
    "\n",
    "# Appliquer sur la colonne 'title'\n",
    "data_fr['title_clean'] = data_fr['title'].apply(clean_title_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "776affba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape (fr): (1133, 1837)\n"
     ]
    }
   ],
   "source": [
    "# Construction de la matrice TF-IDF pour les articles en français en utilisant seulement les titres\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer_fr = TfidfVectorizer(\n",
    "    vocabulary=vocab_fr,  # on utilise le vocabulaire extrait précédemment\n",
    "    max_df=0.8,                 # optionnel, mais sécuritaire\n",
    "    min_df=2,                   # optionnel, mais sécuritaire\n",
    "    ngram_range=(1, 2)          # unigrams et bigrams\n",
    ")\n",
    "\n",
    "# Construction de la matrice TF-IDF\n",
    "tfidf_matrix_fr = vectorizer_fr.fit_transform(data_fr['title_clean'])\n",
    "print(\"TF-IDF matrix shape (fr):\", tfidf_matrix_fr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a590985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\charl\\AppData\\Local\\Temp\\ipykernel_17292\\462268148.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_fr[\"cluster\"] = kmeans.fit_predict(tfidf_matrix_fr)\n"
     ]
    }
   ],
   "source": [
    "# Application du K-means \n",
    "# En regardant les résultats du challenge publiés, on constate que le nombre de clusters utilisé est 10\n",
    "from sklearn.cluster import KMeans\n",
    "k = 10\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "data_fr[\"cluster\"] = kmeans.fit_predict(tfidf_matrix_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "091f6cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer_fr.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a07a89d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 : ontologie, alignement, construction, sémantique, texte, guider, entrer, owl, dédier, relation\n",
      "Cluster 1 : donnée, fouille, flux, base, entrepôt, visualisation, apprentissage, multidimensionnel, textuel, ensemble\n",
      "Cluster 2 : motif, séquentiel, extraction, fréquent, découverte, donnée, contrainte, attribuer, graduel, base\n",
      "Cluster 3 : règle, association, extraction, génération, recherche, classification, comparaison, exception, flou, entrer\n",
      "Cluster 4 : réseau, apprentissage, sémantique, détection, graphe, social, recherche, information, mesure, clustering\n",
      "Cluster 5 : séquence, temporel, série, spatio, événement, motif, extraction, classification, fréquent, flux\n",
      "Cluster 6 : connaissance, extraction, gestion, base, donnée, compétence, information, acquisition, texte, expert\n",
      "Cluster 7 : document, arbre, xml, décision, annotation, structure, recherche, classification, évaluation, classement\n",
      "Cluster 8 : classification, superviser, non, donnée, sélection, image, automatique, visualisation, hiérarchique, variable\n",
      "Cluster 9 : web, sémantique, site, donnée, page, extraction, recherche, mining, document, utilisateur\n"
     ]
    }
   ],
   "source": [
    "# Chaque cluster a un centroïde (un vecteur) qui est la moyenne des vecteurs TF-IDF de tous les documents dans ce cluster.\n",
    "# Chaque dimension du vecteur correspond à un mot de ton vocabulaire.\n",
    "# Plus la valeur dans le centroïde pour un mot est grande, plus ce mot est représentatif des documents du cluster.\n",
    "# Le code prend les n mots avec les plus grandes valeurs dans le centroïde → ce sont ceux qui définissent le cluster.\n",
    "# Du coup le premier mot est le plus proche du thème du cluster\n",
    "import numpy as np\n",
    "\n",
    "def get_top_words_per_cluster(model, terms, n_words=10):\n",
    "    for i, centroid in enumerate(model.cluster_centers_):\n",
    "        top_indices = centroid.argsort()[-n_words:][::-1]\n",
    "        top_terms = [terms[ind] for ind in top_indices]\n",
    "        print(f\"Cluster {i} : {', '.join(top_terms)}\")\n",
    "get_top_words_per_cluster(kmeans, terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bcfa2ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Cluster 0\n",
      "[\"Contraintes prescriptives compatibles avec OWL2-ER pour évaluer la complétude d'ontologies\"\n",
      " \"L'ontologie OntoBiotope pour l'étude de la biodiversité microbienne\"\n",
      " \"Vers une instance française de NELL : chaîne TLN multilingue et modélisation d'ontologie\"]\n",
      "\n",
      "### Cluster 1\n",
      "['Apport de la fouille de données pour la prévention du risque suicidaire'\n",
      " 'Interrogation de données structurellement hétérogènes dans les bases de données orientées documents'\n",
      " \"L'exploitation de données contextuelles pour la recommandation d'hôtels\"]\n",
      "\n",
      "### Cluster 2\n",
      "[\"Découverte de motifs graduels partiellement ordonnés : application aux données d'expériences scientifiques\"\n",
      " 'Echantillonnage de motifs séquentiels sous contrainte sur la norme'\n",
      " 'Fouille de Motifs Graduels Fermés Fréquents Sous Contrainte de la Temporalité']\n",
      "\n",
      "### Cluster 3\n",
      "[\"Définir les catégories de DBpédia avec des règles d'associations et des redescriptions\"\n",
      " \"Sélection ciblée des descripteurs visuels pour la recherche d'images: une approche basée sur les règles d'association\"\n",
      " \"Une approche logique pour la fouille de règles d'association\"]\n",
      "\n",
      "### Cluster 4\n",
      "[\"#Idéo2017 : une plateforme citoyenne dédiée à l'analyse des tweets lors des événements politiques\"\n",
      " 'ALGeoSPF: Un modèle de factorisation basé sur du clustering géographique pour la recommandation de POI'\n",
      " \"Analyse des sentiments à partir des commentaires Facebook publiés en Arabe standard ou dialectal marocain par une approche d'apprentissage automatique\"]\n",
      "\n",
      "### Cluster 5\n",
      "['Exploration et analyses multi-objectifs de séries temporelles de données météorologiques'\n",
      " 'Fouille de motifs temporels négatifs'\n",
      " \"PerForecast : un outil de prévision de l'évolution de séries temporelles pour le planning capacitaire\"]\n",
      "\n",
      "### Cluster 6\n",
      "['Contextualisation de Singularités en Temps-Réel par Extraction de Connaissances du Web des Données'\n",
      " \"Elaboration et utilisation d'une base de connaissances d'un domaine technique.\"\n",
      " \"Extraction de chaînes cohérentes en vue de reconstuire la Trajectoire de l'information\"]\n",
      "\n",
      "### Cluster 7\n",
      "['NFB: protocole de Notarisation des Documents dans la Blockchain'\n",
      " 'Prise en compte de la structure des documents pour une indexation performante'\n",
      " 'Découverte de sous-groupes avec les arbres de recherche de Monte Carlo']\n",
      "\n",
      "### Cluster 8\n",
      "['Apprendre les relations de préférence et de co-occurrence entre les labels en classification multi-labels'\n",
      " 'Classification de Données Complexes par Globalisation de Mesures de Similarité via les Moyennes Quasi-Arithmétiques'\n",
      " 'Prétraitement de données spatialement imprécises pour une classification supervisée basée sur les images satellitaires']\n",
      "\n",
      "### Cluster 9\n",
      "[\"Détection de Singularités en temps-réel par combinaison d'apprentissage automatique et web sémantique basés sur Spark\"\n",
      " \"Universal-endpoint.com : une plateforme d'accès simple au Web des Données\"\n",
      " 'Pharmacovigilance du Web Social par une approche fondée sur les bases de connaissances du Web Sémantique']\n"
     ]
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    print(f\"\\n### Cluster {i}\")\n",
    "    print(data_fr[data_fr[\"cluster\"] == i][\"title\"].head(3).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd3d417e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster\n",
      "4    453\n",
      "1    175\n",
      "6    112\n",
      "8     94\n",
      "3     59\n",
      "0     55\n",
      "5     51\n",
      "2     48\n",
      "7     46\n",
      "9     40\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Affichons le nombre d'articles par cluster\n",
    "print(data_fr['cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a01f205f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Local\\Temp\\ipykernel_17292\\3861666029.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_fr[\"theme\"] = data_fr[\"cluster\"].map(cluster_themes)\n"
     ]
    }
   ],
   "source": [
    "# On rajoute maintenant une colonne thème ou on correspond le thème à chaque cluster\n",
    "cluster_themes = {\n",
    "    0: \"Web Sémantique\",\n",
    "    1: \"Entrepôts de Données\",\n",
    "    2: \"Fouille de Motifs\",\n",
    "    3: \"Règles d'Association\",\n",
    "    4: \"Analyse de Graphes\",\n",
    "    5: \"Flux & Temporalité\",\n",
    "    6: \"Ingénierie des Données\",\n",
    "    7: \"Recherche d'Information\",\n",
    "    8: \"Classification & Clustering\",\n",
    "    9: \"Web Mining\"\n",
    "}\n",
    "\n",
    "data_fr[\"theme\"] = data_fr[\"cluster\"].map(cluster_themes)\n",
    "# On sauvgarde dans le meme fichier clustered_articles_fr.csv\n",
    "data_fr.to_csv(\"clustered_articles_fr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55a742e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fr = data_fr.drop(['cluster'], axis=1)\n",
    "data_fr.to_csv(\"clustered_articles_fr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0c9e27",
   "metadata": {},
   "source": [
    "# Traitement de l'anglais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "da007a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n",
      "{'classifying', 'action', 'genome-wide', 'knn', 'recommender', 'capture', 'ontology', 'non-linear', 'connecion', 'go', 'recherche', 'engagement', 'high', 'visualizing', 'porgy', 'empirical', 'sequence', 'study', 'visualization', 'parameter-free', 'dataset', 'personal', 'effectiveness,', 'categorical', 'dissimilarity', 'strategies', 'reframing', 'problems', '(social)', 'graphs', 'advances', 'nearness', 'experience', 'dynamics:', 'filtering', 'extracting', 'correction', 'inventing', 'syrqus', 'recommendation-based', 'corporate', 'video', 'representative', 'analytics', 'management', 'vs', 'decomposition', 'process', 'exploratoire', 'speed', 'random', 'automatic', 'views', 'ardans', 'applying', 'collaboration', 'analytics,', 'assessing', 'complex', 'modeling', 'analyze', 'neighboring', 'interpreting', 'protein', 'constraint-based', 'to', 'big', 'moi”:', 'mining,', 'deep', 'topology', 'modelling', 'expression', 'implications', 'variability', 'academic', 'incompletely', 'set', 'microblogging', 'attributes', 'spaces', 'aggregative', 'resolution', 'sampling', 'by', 'linked', 'event', 'dtmvic', 'information', 'contextualization', 'relationship', 'cultural', 'and', 'heuristic', 'topological', 'social', 'estimation', 'segmentation', 'mysins', 'evaluation', 'simplified', 'composite', 'pos', 'comparison', 'rough', 'web:', 'initiate', 'binary', 'fisher', 'movement', 'fast', 'constraint', 'inference', 'co-clustering', 'mahout', '&', 'par', 'filling', 'we', 'hints', 'becomes', 'happens', 'detecting', 'answering', 'prospect', 'privacy:', 'latent', 'trees', 'fairness-aware', 'rules', 'logic', 'rewriting', 'tag', 'materialized', 'sciences', 'tag-based', 'past,', 'outlier', 'evaluation:', 'association', 'mining', 'semantics', 'understanding', 'interestingness', 'et', 'gene', 'online', 'autonomous', 'socio-semantic', 'interval-valued', 'application', 'approaches', 'markov', 'data', 'canonical', 'four', 'tulip:', 'internet', 'closed', 'classification', 'intrusions', 'partitioning', 'spatio-temporal', 'density', 'ontologies:', 'sustainable', 'identify', 'large', 'recent', 'smart', 'purchase', 'maintaining', 'avec', 'apps', 'opportunities', 'criteria', 'visualisation,', 'in', \"don't\", 'systems', 'social-attribute', 'musette', 'that', 'method', 'testbeds', 'ultrametricity', 'histograms', 'development', 'xml', 'models', 'human', 'activity', 'tagger', 'resampling', 'user-user', 'library', 'plagiarism', 'relational', 'sets:', 'their', 'semantic', 'grouping', 'compendium:', 'all', 'queries', 'periurban', 'time', 'easily', '«', 'geometry', 'image', 'memory', 'file', 'kernel', 'framework', 'uncertainty', 'semi-interactif', 'reveal?', 'platform', 'de', 'scalable', 'networks', 'spots', 'boost1', 'generalized', 'piecewise', '»', 'analysis', 'window', 'enhanced', 'risk', 'features', 'classes', 'distribué', 'unsupervised', 'component', 'engine', 'reasoning', 'over', 'data:', 'geo-tagged', 'your', 'marketing', 'shift', 'temporal', 'for', 'problem', 'on', '2.0', 'how', 'recommendation', 'behaviours', 'incremental', 'fragments', 'identification', 'scaling', 'can', 'type', 'conversational', '0-1', 'extraction', 'satisfaction', 'context', 'complex,', 'total', 'heuristics', \"hitchhiker's\", 'spatial', 'lattices', 'presence', 'densities', 'hypergraph', 'non-disjoint', 'level', 'conditional', 'rule', 'trajectory', 'service', 'compacts', 'retrospect', 'logiciel', 'coviz', 'small', 'quality', 'its', 'the', 'ssc', 'algorithms', 'android', 'very', 'analytics:', 'clustering', 'model', 'attribute', 'visual', 'real-estate', 'texts', 'approximation', 'assumptions', 'multi-classifier', 'on-line', 'confidence', 'representation', 'algorithm', 'shooting', 'graphes', 'biclustering', 'view', 'customer', 'multi-label', 'early', 'mining:', 'semantics-based', 'conference', 'local', 'hierarchic', 'values', 'experiment', 'using', 'real?', 'through', 'entropy', 'semi-structured', 'unlabelled', 'closed-set-based', 'about', 'crowd', 'informed', 'system', 'word', 'rdf', 'worded', 'point', 'future', 'entropic-genetic', 'present,', 'literary', 'media', '?', 'leveragingweb', 'mesh', 'orange', 'factor', 'applications', 'rules:', 'objective', 'yacaree', 'machine', 'query', 'environments', 'pls', ':', 'access', 'history', 'detection:', 'microarray', 'inweb', 'multiarmed', 'photographs', 'effective', 'solving', 'correlation', 'sentence-phrase-based', 'adaptive', 'a', 'bases', 'influences', 'intrusion', 'statecharts', 'continuous', 'patterns', 'is', '-', 'broad', 'sequential', 'svm', 'communities', 'repository', 'challenges', 'generic', 'currently', 'community', 'approximations', 'make', 'maintenance', 'when', 'summary', 'have', 'topic', 'towards', 'iot', 'user', 'path', 'structured', 'collaborative', 'identifying', 'approach', 'distributions', 'long-range', 'feedback', 'galois', 'relevant', 'svms', 'why?', 'multi-block', 'change', 'k-coclustering', 'analysed', 'hadoop', 'science', 'deduplication', 'ontologies', 'ten', 'stream', 'keyword', 'antipattern', 'heritage', 'underlying', 'probabilistic', 'sites', '“engage', 'enhancing', 'tweets', 'mediating', 'two', 'streams', 'fringe', 'forest', 'gaps', 'guide', 'lattice', 'technique', 'mean-shift', 'question', 'browsing', 'anomalies', 'based', 'revisited', 'sources', 'finding', 'interesting', 'orders', 'leaning', 'bibliographical', 'dawn', 'citation', 'structure', 'documents', 'well', 'novelty', 're-ranking', 'it', 'discretization', 'measuring', 'of', 'content-based', 'model-based', 'cities', 'prediction', 'training', 'services', 'developments', 'discourse:', 'robust', 'egc', 'function', 'distributed', 'indexing', 'graph', 'improvement', 'influencers', 'audit', 'used', 'robot', 'learning', 'meta-actions', 'with', 'dive', 'visuel', 'personalized', 'biological', 'analyse', 'text', 'inférence,', 'years', 'regularized', 'discovery', 'deriving', 'database:', 'sets', 'as', 'search', 'khiops', 'interactions', 'privacy', 'drifted', 'efficient', 'voting', 'optimal', 'mobile', 'genetic', 'knowledge', 'statistical', 'programming', 'sequences', 'combinaison', 'limit', 'anomaly', 'annotated', 'tom:', 'document', 'pattern', 'new', 'from', 'challenge', 'formalism,', 'summarization', 'hybrid', 'everything', 'hci,', 'users', 'self-clustering', 'massive,', 'fusion', 'web', 'annotation', 'an', 'open-domain', 'retrieval', 'subspace', \"d'itemsets\", 'ratings', 'bayesian', 'detection', 'modularization', 'histogram', 'passage', 'driven', 'linear', 'distributedweb', 'what', 'processing', 'power', 'databases', 'evaluating', 'handling', 'significance', 'sparql', 'bandit', 'mobility,'}\n"
     ]
    }
   ],
   "source": [
    "# Récupération du vocabulaire français à partir des titres des articles en anglais\n",
    "# je veux le sauvgarder dans une liste \n",
    "vocab_en = set()\n",
    "for title in data_en['title']:\n",
    "    for word in title.split():\n",
    "        vocab_en.add(word.lower())\n",
    "\n",
    "print (len(vocab_en))\n",
    "print ((vocab_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d6da99eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatisation\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatiser_anglais(texte):\n",
    "    doc = nlp(str(texte).lower())\n",
    "    # On garde le lemme si ce n'est pas une ponctuation ou un stop word\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
    "\n",
    "data_en['title_lemmatize'] = data_en['title'].apply(lemmatiser_anglais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "987dec18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458\n",
      "{'action', 'revisit', 'knn', 'tulip', 'recommender', 'capture', 'ontology', 'connecion', 'hint', 'recherche', 'engagement', 'high', 'socio', 'sequence', 'porgy', 'empirical', 'study', 'visualization', 'dataset', 'personal', 'detect', 'categorical', 'dissimilarity', 'classifier', 'classify', \"d'itemset\", 'real', 'nearness', 'parameter', 'criterion', 'experience', 'filtering', 'correction', 'meta', 'syrqus', 'cluster', 'corporate', 'video', 'management', 'representative', 'vs', 'decomposition', 'process', 'exploratoire', 'speed', 'random', 'compendium', 'spot', 'base', 'automatic', 'ardans', 'personalize', 'collaboration', 'complex', 'modeling', 'opportunity', 'analyze', 'neighboring', 'protein', 'big', 'deep', 'topology', 'modelling', 'expression', 'variability', 'academic', 'incompletely', 'interpret', 'vote', 'set', 'free', 'aggregative', 'microblogge', 'compact', 'resolution', '0', 'past', 'dtmvic', 'event', 'information', 'contextualization', 'maintain', 'relationship', 'cultural', 'heuristic', 'line', 'topological', 'social', 'assumption', 'segmentation', 'estimation', 'evaluation', 'simplified', 'composite', 'pos', 'comparison', 'rough', 'tom', 'initiate', 'binary', 'extract', 'fisher', 'movement', 'fast', 'strategy', 'constraint', 'inference', 'underlie', 'mahout', 'regularize', 'par', 'disjoint', 'measure', 'enhance', 'long', 'link', 'prospect', 'resample', 'latent', 'discourse', 'datum', 'logic', 'year', 'tag', 'spatio', 'wide', 'outlier', 'association', 'mining', 'semantics', 'interestingness', 'et', 'gene', 'online', 'derive', 'autonomous', 'application', 'solve', 'markov', 'data', 'canonical', 'internet', 'classification', 'density', 'coclustere', 'testbed', 'sustainable', 'identify', 'large', 'recent', 'smart', 'purchase', 'avec', 'self', 'lean', 'value', 'feature', 'musette', 'method', 'ultrametricity', 'order', 'development', 'xml', 'human', 'activity', 'tagger', 'scale', 'library', 'plagiarism', 'relational', 'handle', 'mysin', 'mediate', 'semantic', 'grouping', '1', 'periurban', 'space', 'time', 'easily', 'geometry', 'image', 'memory', 'file', 'influencer', 'kernel', 'framework', 'uncertainty', 'khiop', 'platform', 'de', 'scalable', 'boost1', 'generalized', 'influence', 'hitchhiker', 'fragment', 'piecewise', 'inférence', 'reason', 'analysis', 'window', 'evaluate', 'risk', 'distribué', 'unsupervised', 'component', 'engine', 'reasoning', 'marketing', 'shift', 'temporal', 'problem', '2.0', 'recommendation', 'drive', 'incremental', 'semi', 'identification', 'type', 'conversational', 'co', 'extraction', 'satisfaction', 'context', 'browse', 'geo', 'entropic', 'analytic', 'label', 'total', 'spatial', 'presence', 'find', 'hypergraph', 'massive', 'level', 'conditional', 'assess', 'implication', 'rule', 'trajectory', 'service', 'visualize', 'retrospect', 'block', 'logiciel', 'coviz', 'small', 'quality', 'basis', 'range', 'happen', 'ssc', 'android', 'clustering', 'model', 'attribute', 'visual', 'medium', 'approximation', 'confidence', 'representation', 'fairness', 'algorithm', 'graphes', 'biclustering', 'view', 'customer', 'early', 'conference', 'fill', 'local', 'hierarchic', 'experiment', 'entropy', 'unlabelled', 'crowd', 'informed', 'system', 'word', 'dynamic', 'rdf', 'point', 'future', 'k', 'literary', 'leveragingweb', 'mesh', 'orange', 'factor', 'mine', 'partition', 'objective', 'yacaree', 'phrase', 'machine', 'query', 'pls', 'understand', 'invent', 'access', 'history', 'environment', 'microarray', 'inweb', 'effective', 'correlation', 'adaptive', 'intrusion', 'class', 'continuous', 'reveal', 'close', 'broad', 'database', 'sequential', 'svm', 'hci', 'repository', 'advance', 'generic', 'currently', 'community', 'site', 'estate', 'apply', 'distribution', 'maintenance', 'summary', 'ranking', 'topic', 'iot', 'user', 'present', 'statechart', 'path', 'structured', 'collaborative', 'sentence', 'approach', 'feedback', 'galois', 'content', 'relevant', 'svms', 'change', 'genome', 'hadoop', 'science', 'deduplication', 'distribute', 'aware', 'answer', 'stream', 'keyword', 'antipattern', 'heritage', 'probabilistic', 'interactif', 'domain', 'formalism', 'tweet', 'rating', 'network', 'fringe', 'forest', 'guide', 'lattice', 'interval', 'technique', 'question', 'engage', 'mean', 'behaviour', 'app', 'interesting', 'bibliographical', 'dawn', 'citation', 'structure', 'novelty', 'discretization', 'materialize', 'reframe', 'prediction', 'training', 'moi', 'rewrite', 'robust', 'egc', 'function', 'multiarme', 'graph', 'indexing', 'improvement', 'audit', 'robot', 'learning', 'non', 'dive', 'visuel', 'biological', 'analyse', 'text', 'discovery', 'learn', 'search', 'photograph', 'privacy', 'gap', 'efficient', 'voting', 'source', 'optimal', 'mobile', 'genetic', 'knowledge', 'statistical', 'programming', 'combinaison', 'limit', 'anomaly', 'document', 'pattern', 'new', 'challenge', 'summarization', 'hybrid', 'open', 'mobility', 'fusion', 'web', 'annotation', 'retrieval', 'visualisation', 'subspace', 'tree', 'bayesian', 'detection', 'modularization', 'histogram', 'passage', 'linear', 'distributedweb', 'processing', 'city', 'interaction', 'power', 'shoot', 'effectiveness', 'multi', 'significance', 'sparql', 'bandit', 'drift', 'sample', 'annotate'}\n"
     ]
    }
   ],
   "source": [
    "# Affichage après lemmatisation\n",
    "vocab_en = set()\n",
    "for title in data_en['title_lemmatize']:\n",
    "    for word in title.split():\n",
    "        vocab_en.add(word.lower())\n",
    "\n",
    "print (len(vocab_en))\n",
    "print ((vocab_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "955a0f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Désambiguïsation (regroupement de synonymes)\n",
    "\n",
    "def reduire_synonymes(mot):\n",
    "    # On cherche les synonymes du mot\n",
    "    if len(str(mot)) <= 3:\n",
    "        return mot\n",
    "    synsets = wordnet.synsets(mot)\n",
    "    if synsets:\n",
    "        # On récupère le nom du premier concept (le plus commun)\n",
    "        # ex: 'big' et 'large' pourraient tous deux renvoyer 'large'\n",
    "        return synsets[0].lemmas()[0].name()\n",
    "    return mot\n",
    "\n",
    "def traiter_synonymes(texte_lemmatize):\n",
    "    mots = str(texte_lemmatize).split()\n",
    "    # Remplace chaque mot par son synonyme pivot\n",
    "    mots_unifies = [reduire_synonymes(m) for m in mots]\n",
    "    return \" \".join(mots_unifies)\n",
    "\n",
    "data_en['title_clean'] = data_en['title_lemmatize'].apply(traiter_synonymes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d00aa496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\n",
      "{'action', 'revisit', 'knn', 'tulip', 'recommender', 'capture', 'ontology', 'connecion', 'hint', 'high', 'socio', 'sequence', 'porgy', 'empirical', 'dataset', 'personal', 'property', 'fisherman', 'detect', 'categorical', 'dissimilarity', 'classifier', 'tilt', 'classify', \"d'itemset\", 'nearness', 'parameter', 'experience', 'correction', 'real_number', 'meta', 'syrqus', 'corporate', 'video', 'management', 'representative', 'vs', 'decomposition', 'exploratoire', 'speed', 'random', 'base', 'topographic_point', 'ardans', 'personalize', 'collaboration', 'complex', 'modeling', 'moral_force', 'opportunity', 'analyze', 'note', 'optimum', 'protein', 'big', 'academician', 'deep', 'topology', 'expression', 'variability', 'incompletely', 'interpret', 'vote', 'set', 'semifinal', 'free', 'microblogge', 'compact', 'resolution', '0', 'past', 'dtmvic', 'event', 'information', 'contextualization', 'relationship', 'cultural', 'heuristic', 'line', 'topological', 'evaluation', 'sociable', 'pos', 'behavior', 'comparison', 'rough', 'hierarchical', 'tom', 'fast', 'constraint', 'inference', 'underlie', 'mahout', 'loanblend', 'par', 'measure', 'enhance', 'estimate', 'link', 'prospect', 'resample', 'inform', 'latent', 'discourse', 'datum', 'logic', 'year', 'tag', 'depository', 'spatio', 'wide', 'outlier', 'association', 'deduce', 'mining', 'semantics', 'et', 'gene', 'autonomous', 'automaton', 'application', 'solve', 'markov', 'bunch', 'data', 'footing', 'hanker', 'internet', 'density', 'coclustere', 'testbed', 'sustainable', 'identify', 'large', 'smart', 'purchase', 'avec', 'self', 'use', 'value', 'feature', 'musette', 'method', 'ultrametricity', 'order', 'development', 'xml', 'activity', 'tagger', 'scale', 'library', 'plagiarism', 'relational', 'handle', 'mysin', 'semantic', '1', 'uncover', 'prosecute', 'periurban', 'space', 'time', 'easily', 'geometry', 'image', 'memory', 'file', 'influencer', 'kernel', 'binary_star', 'uncertainty', 'khiop', 'platform', 'de', 'scalable', 'boost1', 'influence', 'hitchhiker', 'fragment', 'piecewise', 'inférence', 'selling', 'canonic', 'reason', 'analysis', 'window', 'usher', 'distribué', 'unsupervised', 'component', 'engine', 'homo', 'reasoning', 'familial', 'shift', 'appraisal', 'problem', '2.0', 'cognition', 'recommendation', 'drive', 'incremental', 'cleavage', 'type', 'co', 'extraction', 'satisfaction', 'context', 'browse', 'colloquial', 'entropic', 'analytic', 'geo', 'label', 'time_interval', 'stopping_point', 'spatial', 'battle', 'presence', 'hypergraph', 'massive', 'conditional', 'interest', 'collection', 'rule', 'survey', 'trajectory', 'service', 'visualize', 'retrospect', 'block', 'generalize', 'coviz', 'assurance', 'small', 'holocene', 'logiciel', 'quality', 'happen', 'ssc', 'android', 'presently', 'model', 'medium', 'simplify', 'on-line', 'representation', 'freshness', 'fairness', 'algorithm', 'procedure', 'biclustering', 'customer', 'early', 'infusion', 'conference', 'fill', 'local', 'neighbor', 'experiment', 'position', 'crowd', 'system', 'word', 'rdf', 'designation', 'point', 'future', 'disassociate', 'k', 'literary', 'mold', 'leveragingweb', 'progress', 'mesh', 'orange', 'factor', 'care', 'mine', 'partition', 'way', 'yacaree', 'exquisite', 'phrase', 'machine', 'pls', 'understand', 'invent', 'history', 'scheme', 'environment', 'microarray', 'inweb', 'effective', 'correlation', 'adaptive', 'class', 'continuous', 'ocular', 'intercede', 'broad', 'database', 'novice', 'svm', 'hci', 'beginning', 'generic', 'community', 'site', 'estate', 'distribution', 'deduction', 'summary', 'keep', 'ranking', 'iot', 'user', 'present', 'statechart', 'collaborative', 'sentence', 'approach', 'subject', 'feedback', 'galois', 'content', 'relevant', 'svms', 'change', 'genome', 'hadoop', 'science', 'deduplication', 'distribute', 'entree', 'aware', 'aggregate', 'answer', 'stream', 'consecutive', 'keyword', 'antipattern', 'heritage', 'probabilistic', 'interactif', 'bibliographic', 'formalism', 'tweet', 'motion', 'network', 'regulate', 'forest', 'lattice', 'technique', 'question', 'degree', 'mean', 'app', 'unlabeled', 'dawn', 'citation', 'structure', 'discretization', 'periphery', 'visual_image', 'reframe', 'prediction', 'training', 'moi', 'rewrite', 'robust', 'egc', 'premise', 'function', 'multiarme', 'graph', 'indexing', 'improvement', 'learning', 'non', 'visuel', 'biological', 'invasion', 'text', 'discovery', 'learn', 'sum', 'standard', 'search', 'scope', 'photograph', 'privacy', 'gap', 'categorization', 'efficient', 'scheduling', 'mobile', 'statistical', 'automatic_rifle', 'combinaison', 'audited_account', 'limit', 'anomaly', 'hazard', 'honkytonk', 'document', 'new', 'challenge', 'summarization', 'group', 'open', 'mobility', 'aim', 'fusion', 'web', 'retrieval', 'subspace', 'form', 'tree', 'bayesian', 'detection', 'modularization', 'histogram', 'passage', 'linear', 'sphere', 'distributedweb', 'processing', 'city', 'interaction', 'power', 'shoot', 'temporal_role', 'effectiveness', 'multi', 'significance', 'sparql', 'bandit', 'filter', 'drift', 'sample', 'annotate'}\n"
     ]
    }
   ],
   "source": [
    "# Affichage après désambiguïsation (regroupement de synonymes)\n",
    "vocab_en = set()\n",
    "for title in data_en['title_clean']:\n",
    "    for word in title.split():\n",
    "        vocab_en.add(word.lower())\n",
    "\n",
    "print (len(vocab_en))\n",
    "print ((vocab_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8dd5e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     ------- -------------------------------- 2.4/12.8 MB 9.0 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.2/12.8 MB 9.0 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 6.0/12.8 MB 9.2 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.9/12.8 MB 9.0 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 9.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.5/12.8 MB 8.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 8.5 MB/s  0:00:01\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "90d4b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape (en): (122, 442)\n"
     ]
    }
   ],
   "source": [
    "# Construction de la matrice TF-IDF pour les articles en anglais en utilisant seulement les titres\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer_en = TfidfVectorizer(\n",
    "    vocabulary=vocab_en,  # on utilise le vocabulaire extrait précédemment\n",
    "    max_df=0.8,                 # optionnel, mais sécuritaire\n",
    "    min_df=2,                   # optionnel, mais sécuritaire\n",
    "    ngram_range=(1, 2)          # unigrams et bigrams\n",
    ")\n",
    "\n",
    "# Construction de la matrice TF-IDF\n",
    "tfidf_matrix_en = vectorizer_en.fit_transform(data_en['title_clean'])\n",
    "print(\"TF-IDF matrix shape (en):\", tfidf_matrix_en.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "159dc25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\charl\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "inertia = []\n",
    "K = range(2, 10)\n",
    "\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(tfidf_matrix_en)\n",
    "    inertia.append(kmeans.inertia_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c5ad2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer_en.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0cf58430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 : user, evaluation, retrieval, microblogge, colloquial, interaction, site, passage, open, ranking\n",
      "Cluster 1 : network, model, ontology, learning, property, community, sociable, graph, machine, mine\n",
      "Cluster 2 : extraction, information, semantic, text, complex, compact, kernel, system, intercede, processing\n",
      "Cluster 3 : rule, discovery, association, set, base, database, stopping_point, action, relational, representative\n",
      "Cluster 4 : stream, detect, data, anomaly, line, bunch, datum, detection, academician, plagiarism\n",
      "Cluster 5 : datum, mining, constraint, big, categorization, scheduling, challenge, fusion, privacy, learn\n",
      "Cluster 6 : analytic, ocular, problem, base, challenge, system, solve, bibliographic, keep, application\n",
      "Cluster 7 : detection, outlier, collaborative, invasion, mobile, automaton, autonomous, small, antipattern, experiment\n",
      "Cluster 8 : bunch, familial, heuristic, algorithm, entropic, base, network, visuel, interactif, ssc\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_top_words_per_cluster(model, terms, n_words=10):\n",
    "    for i, centroid in enumerate(model.cluster_centers_):\n",
    "        top_indices = centroid.argsort()[-n_words:][::-1]\n",
    "        top_terms = [terms[ind] for ind in top_indices]\n",
    "        print(f\"Cluster {i} : {', '.join(top_terms)}\")\n",
    "get_top_words_per_cluster(kmeans, terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eb5260b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application du K-means \n",
    "# En regardant les résultats du challenge publiés, on constate que le nombre de clusters utilisé est 10\n",
    "k = 9\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "data_en[\"cluster\"] = kmeans.fit_predict(tfidf_matrix_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c857e93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Cluster 0\n",
      "['Enhanced user-user collaborative filtering recommendation algorithm based on semantic ratings'\n",
      " '“Engage moi”: From retrieval effectiveness, user satisfaction to user engagement'\n",
      " 'A Relevant Passage Retrieval and Re-ranking Approach for Open-Domain Question Answering'\n",
      " 'Using Social Conversational Context For Detecting Users Interactions on Microblogging Sites'\n",
      " 'User Evaluation: Why?']\n",
      "\n",
      "### Cluster 1\n",
      "['Big Data for understanding human dynamics: the power of networks'\n",
      " 'Community structure in complex networks'\n",
      " 'Long-range influences in (social) networks'\n",
      " 'Reframing for Non-Linear Dataset Shift'\n",
      " 'Temporal hints in the cultural heritage discourse: what can an ontology of time as it is worded reveal?'\n",
      " 'Machine Learning Based Classification of Android Apps through Text Features'\n",
      " 'Machine Learning for the Semantic Web: filling the gaps in Ontology Mining'\n",
      " 'Analyse exploratoire par k-Coclustering avec Khiops CoViz'\n",
      " 'TOM: A library for topic modeling and browsing'\n",
      " 'A Framework for Mesh Segmentation and Annotation using Ontologies'\n",
      " 'LeveragingWeb 2.0 for Informed Real-Estate Services'\n",
      " 'To initiate a corporate memory with a knowledge compendium: ten years of learning from experience with the Ardans method'\n",
      " 'Visualizing Shooting Spots using Geo-tagged Photographs from Social Media Sites'\n",
      " 'Incremental learning with latent factor models for attribute prediction in social-attribute networks'\n",
      " 'Mining the Crowd' \"The Hitchhiker's Guide to Ontology\"\n",
      " 'Unsupervised Video Tag Correction System'\n",
      " 'Community Detection in Social Networks with Attribute and Relationship Data'\n",
      " 'Development of a distributed recommender system using the Hadoop Framework'\n",
      " 'Evaluating Bayesian Networks by Sampling with Simplified Assumptions'\n",
      " 'Early Classification on Temporal Sequences'\n",
      " 'Reasoning about the learning process'\n",
      " 'Towards a DistributedWeb Search Engine'\n",
      " 'Applying Markov Logic to Document Annotation and Citation Deduplication'\n",
      " 'Identifying the Presence of Communities in Complex Networks Through Topological Decomposition and Component Densities'\n",
      " 'Protein Graph Repository'\n",
      " 'Tulip: a Scalable Graph Visualization Framework'\n",
      " 'A Contextualization Service for a Personalized Access Model'\n",
      " 'Aggregative and Neighboring Approximations to Query Semi-Structured Documents'\n",
      " 'Discretization of Continuous Features by Resampling'\n",
      " 'From Mining the Web to Inventing the New Sciences Underlying the Internet'\n",
      " 'SyRQuS - Recherche par combinaison de graphes RDF'\n",
      " 'Classifying XML Materialized Views for their maintenance on distributed Web sources'\n",
      " 'A robust method for partitioning the values of categorical attributes'\n",
      " 'How well go Lattice algorithms on currently used machine leaning TestBeds ?'\n",
      " 'MUSETTE : a framework for knowledge capture from experience']\n",
      "\n",
      "### Cluster 2\n",
      "['Deep Dive on Smart Cities by Scaling Reasoning and Interpreting the Semantics of IoT'\n",
      " 'Comparison of linear modularization criteria using the relational formalism, an approach to easily identify resolution limit'\n",
      " 'Towards Linked Data Extraction From Tweets'\n",
      " 'A POS Tagger analysed in collaboration environments and literary texts'\n",
      " 'Non-disjoint grouping of text documents based Word Sequence Kernel'\n",
      " 'Biological event extraction using SVM and composite kernel function'\n",
      " 'Complex Information Processing'\n",
      " 'Mysins : Make Your Semantic INformation System'\n",
      " 'Enhancing Personal File Retrieval in Semantic File Systems with Tag-Based Context'\n",
      " \"Extraction d'itemsets compacts\"\n",
      " 'Structure Inference of Bayesian Networks from Data: A New Approach Based on Generalized Conditional Entropy'\n",
      " 'Extraction of text summary using latent semantic indexing and information retrieval technique : comparison of four strategies'\n",
      " 'Mediating the Semantic Web']\n",
      "\n",
      "### Cluster 3\n",
      "['Recommendation-based Keyword Search over Relational Databases'\n",
      " 'A Clustering Based Approach for Type Discovery in RDF Data Sources'\n",
      " 'Representative training sets for classification and the variability of empirical distributions'\n",
      " 'Closed-set-based Discovery of Representative Association Rules Revisited'\n",
      " 'Parameter-free association rule mining with yacaree'\n",
      " 'Action Rules and Meta-actions'\n",
      " 'Objective Novelty of Association Rules: Measuring the Confidence Boost1'\n",
      " 'Probabilistic Multi-classifier by SVMs from voting rule to voting features'\n",
      " 'A spatial rough set for extracting the periurban fringe'\n",
      " 'Mining Implications from Lattices of Closed Trees'\n",
      " 'Finding interesting queries in relational databases'\n",
      " 'Optimal histogram representation of large data sets: Fisher vs piecewise linear approximation'\n",
      " 'Biclustering of Gene Expression Data Based on Local Nearness'\n",
      " 'Finding fragments of orders and total orders from 0-1 data'\n",
      " 'A Galois connecion semantics-based approach for deriving generic bases of association rules']\n",
      "\n",
      "### Cluster 4\n",
      "['A two level co-clustering algorithm for very large data sets'\n",
      " 'A Hybrid Approach for Detecting Influencers in Social Media'\n",
      " 'Detecting Academic Plagiarism with Graphs'\n",
      " 'Data stream summarization by on-line histograms clustering'\n",
      " 'Density estimation on data streams : an application to Change Detection'\n",
      " 'Detecting Anomalies in Data Streams using Statecharts'\n",
      " 'Online and Adaptive Anomaly Detection: Detecting Intrusions in Unlabelled Audit Data Streams'\n",
      " 'Semantics of Spatial Window over Spatio-Temporal Data Stream']\n",
      "\n",
      "### Cluster 5\n",
      "['Fairness-Aware Data Mining'\n",
      " 'Learning from Massive, Incompletely annotated & Structured Data'\n",
      " 'Topic modeling and hypergraph mining to analyze the EGC conference history'\n",
      " 'Towards generic and efficient constraint-based mining, a constraint programming approach'\n",
      " 'Big Data and the Dawn of Algorithms in Everything'\n",
      " \"Big Data is all about data that we don't have\"\n",
      " 'Feedback - Study and Improvement of the Random Forest of the Mahout library in the context of marketing data of Orange'\n",
      " 'Linked Data Annotation and Fusion driven by Data Quality Evaluation'\n",
      " 'Mining Classes by Multi-label Classification'\n",
      " 'Ultrametricity of Dissimilarity Spaces and Its Significance for Data Mining'\n",
      " 'Automatic correction of SVM for drifted data classification'\n",
      " 'Broad Data: What happens when the Web of Data becomes real?'\n",
      " 'PLS path modeling and regularized generalized canonical correlation analysis for multi-block data analysis'\n",
      " 'Relational Learning from Spatial Data: Retrospect and Prospect'\n",
      " 'Mobility, Data Mining and Privacy: Mining Human Movement Patterns from Trajectory Data'\n",
      " 'Pattern Mining: The Past, Present, and Future'\n",
      " 'Assessing the uncertainty in knn Data Fusion'\n",
      " 'Constraint Programming for Data Mining'\n",
      " 'Handling Texts ? A Challenge for Data Mining'\n",
      " 'Logiciel « DtmVic » Data and Text Mining: Visualisation, Inférence, Classification'\n",
      " 'Privacy and Data Mining: New Developments and Challenges'\n",
      " 'Data mining for activity extraction in video data'\n",
      " 'Interestingness in Data Mining'\n",
      " 'Microarray data mining : recent advances']\n",
      "\n",
      "### Cluster 6\n",
      "['PORGY : a Visual Analytics Platform for System Modelling and Analysis Based on Graph Rewriting'\n",
      " 'Challenges and Opportunities in HCI, Visual Analytics and Knowledge Management for the development of Sustainable Cities'\n",
      " 'Towards a New Science of Big Data Analytics, based on the Geometry and the Topology of Complex, Hierarchic Systems'\n",
      " 'Solving Problems with Visual Analytics: Challenges and Applications'\n",
      " 'Visual Sentence-Phrase-Based Document Representation for Effective and Efficient Content-Based Image Retrieval'\n",
      " 'An approach for handling risk and uncertainty in multiarmed bandit problems'\n",
      " 'Maintaining an Online Bibliographical Database: The Problem of Data Quality']\n",
      "\n",
      "### Cluster 7\n",
      "['Antipattern Detection inWeb Ontologies: an Experiment using SPARQL Queries'\n",
      " 'Human Detection by a Small Autonomous Mobile Robot'\n",
      " 'Binary Sequences and Association Graphs for Fast Detection of Sequential Patterns'\n",
      " 'Collaborative Outlier Mining for Intrusion Detection']\n",
      "\n",
      "### Cluster 8\n",
      "['Mean-shift : Clustering scalable et distribué'\n",
      " 'Clustering visuel semi-interactif'\n",
      " 'Mining Genetic Interactions in Genome-Wide Association Study'\n",
      " 'Topological Decomposition and Heuristics for High Speed Clustering of Complex Networks'\n",
      " 'Entropic-Genetic Clustering'\n",
      " 'Point of View Based Clustering of Socio-Semantic Networks'\n",
      " 'Recent Advances in Partitioning Clustering Algorithms for Interval-Valued Data'\n",
      " 'Self-Clustering for Identification of Customer Purchase Behaviours'\n",
      " 'Clustering : from model-based approaches to heuristic algorithms'\n",
      " 'SSC : Statistical Subspace Clustering']\n"
     ]
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    print(f\"\\n### Cluster {i}\")\n",
    "    print(data_en[data_en[\"cluster\"] == i][\"title\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bfdbc5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de documents par cluster :\n",
      "------------------------------\n",
      "Cluster 0      : 5 documents\n",
      "Cluster 1      : 36 documents\n",
      "Cluster 2      : 13 documents\n",
      "Cluster 3      : 15 documents\n",
      "Cluster 4      : 8 documents\n",
      "Cluster 5      : 24 documents\n",
      "Cluster 6      : 7 documents\n",
      "Cluster 7      : 4 documents\n",
      "Cluster 8      : 10 documents\n"
     ]
    }
   ],
   "source": [
    "# 1. Compter le nombre de titres par cluster\n",
    "counts = data_en['cluster'].value_counts().sort_index()\n",
    "\n",
    "# 2. Affichage propre\n",
    "print(\"Nombre de documents par cluster :\")\n",
    "print(\"-\" * 30)\n",
    "for cluster_id, count in counts.items():\n",
    "    if cluster_id == -1:\n",
    "        print(f\"Bruit (Noise -1) : {count} documents\")\n",
    "    else:\n",
    "        print(f\"Cluster {cluster_id}      : {count} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9a021287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Cluster 0 : Recherche d'Information\n",
      "['Enhanced user-user collaborative filtering recommendation algorithm based on semantic ratings'\n",
      " '“Engage moi”: From retrieval effectiveness, user satisfaction to user engagement'\n",
      " 'A Relevant Passage Retrieval and Re-ranking Approach for Open-Domain Question Answering'\n",
      " 'Using Social Conversational Context For Detecting Users Interactions on Microblogging Sites'\n",
      " 'User Evaluation: Why?']\n",
      "\n",
      "### Cluster 1 : Analyse de Graphes\n",
      "['Big Data for understanding human dynamics: the power of networks'\n",
      " 'Community structure in complex networks'\n",
      " 'Long-range influences in (social) networks'\n",
      " 'Reframing for Non-Linear Dataset Shift'\n",
      " 'Temporal hints in the cultural heritage discourse: what can an ontology of time as it is worded reveal?'\n",
      " 'Machine Learning Based Classification of Android Apps through Text Features'\n",
      " 'Machine Learning for the Semantic Web: filling the gaps in Ontology Mining'\n",
      " 'Analyse exploratoire par k-Coclustering avec Khiops CoViz'\n",
      " 'TOM: A library for topic modeling and browsing'\n",
      " 'A Framework for Mesh Segmentation and Annotation using Ontologies'\n",
      " 'LeveragingWeb 2.0 for Informed Real-Estate Services'\n",
      " 'To initiate a corporate memory with a knowledge compendium: ten years of learning from experience with the Ardans method'\n",
      " 'Visualizing Shooting Spots using Geo-tagged Photographs from Social Media Sites'\n",
      " 'Incremental learning with latent factor models for attribute prediction in social-attribute networks'\n",
      " 'Mining the Crowd' \"The Hitchhiker's Guide to Ontology\"\n",
      " 'Unsupervised Video Tag Correction System'\n",
      " 'Community Detection in Social Networks with Attribute and Relationship Data'\n",
      " 'Development of a distributed recommender system using the Hadoop Framework'\n",
      " 'Evaluating Bayesian Networks by Sampling with Simplified Assumptions'\n",
      " 'Early Classification on Temporal Sequences'\n",
      " 'Reasoning about the learning process'\n",
      " 'Towards a DistributedWeb Search Engine'\n",
      " 'Applying Markov Logic to Document Annotation and Citation Deduplication'\n",
      " 'Identifying the Presence of Communities in Complex Networks Through Topological Decomposition and Component Densities'\n",
      " 'Protein Graph Repository'\n",
      " 'Tulip: a Scalable Graph Visualization Framework'\n",
      " 'A Contextualization Service for a Personalized Access Model'\n",
      " 'Aggregative and Neighboring Approximations to Query Semi-Structured Documents'\n",
      " 'Discretization of Continuous Features by Resampling'\n",
      " 'From Mining the Web to Inventing the New Sciences Underlying the Internet'\n",
      " 'SyRQuS - Recherche par combinaison de graphes RDF'\n",
      " 'Classifying XML Materialized Views for their maintenance on distributed Web sources'\n",
      " 'A robust method for partitioning the values of categorical attributes'\n",
      " 'How well go Lattice algorithms on currently used machine leaning TestBeds ?'\n",
      " 'MUSETTE : a framework for knowledge capture from experience']\n",
      "\n",
      "### Cluster 2 : Web sémantique\n",
      "['Deep Dive on Smart Cities by Scaling Reasoning and Interpreting the Semantics of IoT'\n",
      " 'Comparison of linear modularization criteria using the relational formalism, an approach to easily identify resolution limit'\n",
      " 'Towards Linked Data Extraction From Tweets'\n",
      " 'A POS Tagger analysed in collaboration environments and literary texts'\n",
      " 'Non-disjoint grouping of text documents based Word Sequence Kernel'\n",
      " 'Biological event extraction using SVM and composite kernel function'\n",
      " 'Complex Information Processing'\n",
      " 'Mysins : Make Your Semantic INformation System'\n",
      " 'Enhancing Personal File Retrieval in Semantic File Systems with Tag-Based Context'\n",
      " \"Extraction d'itemsets compacts\"\n",
      " 'Structure Inference of Bayesian Networks from Data: A New Approach Based on Generalized Conditional Entropy'\n",
      " 'Extraction of text summary using latent semantic indexing and information retrieval technique : comparison of four strategies'\n",
      " 'Mediating the Semantic Web']\n",
      "\n",
      "### Cluster 3 : Règles d'Association\n",
      "['Recommendation-based Keyword Search over Relational Databases'\n",
      " 'A Clustering Based Approach for Type Discovery in RDF Data Sources'\n",
      " 'Representative training sets for classification and the variability of empirical distributions'\n",
      " 'Closed-set-based Discovery of Representative Association Rules Revisited'\n",
      " 'Parameter-free association rule mining with yacaree'\n",
      " 'Action Rules and Meta-actions'\n",
      " 'Objective Novelty of Association Rules: Measuring the Confidence Boost1'\n",
      " 'Probabilistic Multi-classifier by SVMs from voting rule to voting features'\n",
      " 'A spatial rough set for extracting the periurban fringe'\n",
      " 'Mining Implications from Lattices of Closed Trees'\n",
      " 'Finding interesting queries in relational databases'\n",
      " 'Optimal histogram representation of large data sets: Fisher vs piecewise linear approximation'\n",
      " 'Biclustering of Gene Expression Data Based on Local Nearness'\n",
      " 'Finding fragments of orders and total orders from 0-1 data'\n",
      " 'A Galois connecion semantics-based approach for deriving generic bases of association rules']\n",
      "\n",
      "### Cluster 4 : Flux & Temporalité\n",
      "['A two level co-clustering algorithm for very large data sets'\n",
      " 'A Hybrid Approach for Detecting Influencers in Social Media'\n",
      " 'Detecting Academic Plagiarism with Graphs'\n",
      " 'Data stream summarization by on-line histograms clustering'\n",
      " 'Density estimation on data streams : an application to Change Detection'\n",
      " 'Detecting Anomalies in Data Streams using Statecharts'\n",
      " 'Online and Adaptive Anomaly Detection: Detecting Intrusions in Unlabelled Audit Data Streams'\n",
      " 'Semantics of Spatial Window over Spatio-Temporal Data Stream']\n",
      "\n",
      "### Cluster 5 : Big Data\n",
      "['Fairness-Aware Data Mining'\n",
      " 'Learning from Massive, Incompletely annotated & Structured Data'\n",
      " 'Topic modeling and hypergraph mining to analyze the EGC conference history'\n",
      " 'Towards generic and efficient constraint-based mining, a constraint programming approach'\n",
      " 'Big Data and the Dawn of Algorithms in Everything'\n",
      " \"Big Data is all about data that we don't have\"\n",
      " 'Feedback - Study and Improvement of the Random Forest of the Mahout library in the context of marketing data of Orange'\n",
      " 'Linked Data Annotation and Fusion driven by Data Quality Evaluation'\n",
      " 'Mining Classes by Multi-label Classification'\n",
      " 'Ultrametricity of Dissimilarity Spaces and Its Significance for Data Mining'\n",
      " 'Automatic correction of SVM for drifted data classification'\n",
      " 'Broad Data: What happens when the Web of Data becomes real?'\n",
      " 'PLS path modeling and regularized generalized canonical correlation analysis for multi-block data analysis'\n",
      " 'Relational Learning from Spatial Data: Retrospect and Prospect'\n",
      " 'Mobility, Data Mining and Privacy: Mining Human Movement Patterns from Trajectory Data'\n",
      " 'Pattern Mining: The Past, Present, and Future'\n",
      " 'Assessing the uncertainty in knn Data Fusion'\n",
      " 'Constraint Programming for Data Mining'\n",
      " 'Handling Texts ? A Challenge for Data Mining'\n",
      " 'Logiciel « DtmVic » Data and Text Mining: Visualisation, Inférence, Classification'\n",
      " 'Privacy and Data Mining: New Developments and Challenges'\n",
      " 'Data mining for activity extraction in video data'\n",
      " 'Interestingness in Data Mining'\n",
      " 'Microarray data mining : recent advances']\n",
      "\n",
      "### Cluster 6 : Visualisation\n",
      "['PORGY : a Visual Analytics Platform for System Modelling and Analysis Based on Graph Rewriting'\n",
      " 'Challenges and Opportunities in HCI, Visual Analytics and Knowledge Management for the development of Sustainable Cities'\n",
      " 'Towards a New Science of Big Data Analytics, based on the Geometry and the Topology of Complex, Hierarchic Systems'\n",
      " 'Solving Problems with Visual Analytics: Challenges and Applications'\n",
      " 'Visual Sentence-Phrase-Based Document Representation for Effective and Efficient Content-Based Image Retrieval'\n",
      " 'An approach for handling risk and uncertainty in multiarmed bandit problems'\n",
      " 'Maintaining an Online Bibliographical Database: The Problem of Data Quality']\n",
      "\n",
      "### Cluster 7 : Fouille de Motifs\n",
      "['Antipattern Detection inWeb Ontologies: an Experiment using SPARQL Queries'\n",
      " 'Human Detection by a Small Autonomous Mobile Robot'\n",
      " 'Binary Sequences and Association Graphs for Fast Detection of Sequential Patterns'\n",
      " 'Collaborative Outlier Mining for Intrusion Detection']\n",
      "\n",
      "### Cluster 8 : Classification & Clustering\n",
      "['Mean-shift : Clustering scalable et distribué'\n",
      " 'Clustering visuel semi-interactif'\n",
      " 'Mining Genetic Interactions in Genome-Wide Association Study'\n",
      " 'Topological Decomposition and Heuristics for High Speed Clustering of Complex Networks'\n",
      " 'Entropic-Genetic Clustering'\n",
      " 'Point of View Based Clustering of Socio-Semantic Networks'\n",
      " 'Recent Advances in Partitioning Clustering Algorithms for Interval-Valued Data'\n",
      " 'Self-Clustering for Identification of Customer Purchase Behaviours'\n",
      " 'Clustering : from model-based approaches to heuristic algorithms'\n",
      " 'SSC : Statistical Subspace Clustering']\n"
     ]
    }
   ],
   "source": [
    "# Association des thèmes\n",
    "mapping_clusters = {\n",
    "    0: \"Recherche d'Information\",\n",
    "    1: \"Analyse de Graphes\",\n",
    "    2: \"Web sémantique\",\n",
    "    3: \"Règles d'Association\",\n",
    "    4: \"Flux & Temporalité\",\n",
    "    5: \"Big Data\",\n",
    "    6: \"Visualisation\",\n",
    "    7: \"Fouille de Motifs\",\n",
    "    8: \"Classification & Clustering\"\n",
    "}\n",
    "\n",
    "data_en['theme'] = data_en['cluster'].map(mapping_clusters)\n",
    "\n",
    "for i in range(k):\n",
    "    theme_nom = mapping_clusters.get(i, \"Thème non défini\")\n",
    "    print(f\"\\n### Cluster {i} : {theme_nom}\")\n",
    "    print(data_en[data_en[\"cluster\"] == i][\"title\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f696061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export csv\n",
    "data_en = data_en.drop(['cluster', 'title_lemmatize'], axis=1)\n",
    "#data_en = data_en.drop(['title_clear'], axis=1)\n",
    "data_en.to_csv(\"clustered_articles_en.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578c42e0",
   "metadata": {},
   "source": [
    "# Merge des deux csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "25ae9811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement\n",
    "data_fr = pd.read_csv('clustered_articles_fr.csv', quotechar='\"', skipinitialspace=True)\n",
    "data_en = pd.read_csv('clustered_articles_en.csv', quotechar='\"', skipinitialspace=True)\n",
    "\n",
    "# Fusionner\n",
    "df_final = pd.concat([data_fr, data_en], ignore_index=True)\n",
    "\n",
    "# Sauvegarder le résultat\n",
    "df_final.to_csv('clustered_articles.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
